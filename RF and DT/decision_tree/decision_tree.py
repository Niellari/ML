from typing import Optional

import numpy as np

from criterio import Criterion, GiniCriterion, EntropyCriterion, MSECriterion
from tree_node import TreeNode


class DecisionTree:
    def __init__(self, max_depth: int = 10, min_leaf_size: int = 5, min_improvement: Optional[float] = None):
        self.criterion = None
        self.max_depth = max_depth
        self.min_leaf_size = min_leaf_size
        self.min_improvement = min_improvement


    def _build_nodes(self, x: np.ndarray, y: np.ndarray, criterion: Criterion, indices: np.ndarray, node: TreeNode):
        """
        Builds tree recursively

        Parameters
        ----------
        x : samples in node, np.ndarray.shape = (n_samples, n_features)
        y : target values, np.ndarray.shape = (n_samples, )
        criterion : criterion to split by, Criterion
        indices : samples' indices in node,
            np.ndarray.shape = (n_samples, )
            nd.ndarray.dtype = int
        node : current node to split, TreeNode
        """
        if self.max_depth is not None and self.max_depth <= node.depth:
            node.set_predictions(criterion.get_predict_val(y[indices]))
            return
        if len(np.unique(y[indices])) <= 1:
            node.set_predictions(criterion.get_predict_val(y[indices]))
            return
        if self.min_leaf_size is not None and self.min_leaf_size >= len(indices):
            node.set_predictions(criterion.get_predict_val(y[indices]))
            return

        node.find_best_split(x[indices], y[indices], criterion)
        if self.min_improvement is not None and self.min_improvement >= node.q_value_max:
            node.set_predictions(criterion.get_predict_val(y[indices]))
            return
        node.create_children()
        mask = node.get_best_split_mask(x[indices])
        self._build_nodes(x, y, criterion, indices[mask], node.left_child)
        self._build_nodes(x, y, criterion, indices[~mask], node.right_child)

    def _get_nodes_predictions(self, x: np.ndarray, predictions: np.ndarray, indices: np.ndarray, node: TreeNode):
        if node.is_terminal():
            predictions[indices] = node.predictions
            return
        mask = node.get_best_split_mask(x[indices])
        self._get_nodes_predictions(x, predictions, indices[mask], node.left_child)
        self._get_nodes_predictions(x, predictions, indices[~mask], node.right_child)


class ClassificationDecisionTree(DecisionTree):
    def __init__(self, criterion: str = "gini", **kwargs):
        super().__init__(**kwargs)

        if criterion not in ["gini", "entropy"]:
            raise ValueError('Unsupported criterion', criterion)
        self.criterion = criterion
        self.n_classes = 0
        self.n_features = 0
        self.root = None

    def fit(self, x, y):
        self.n_classes = np.unique(y).shape[0]
        self.n_features = x.shape[1]
        criterion = None
        if self.criterion == "gini":
            criterion = GiniCriterion(self.n_classes)
        elif self.criterion == "entropy":
            criterion = EntropyCriterion(self.n_classes)
        self.root = TreeNode(depth=0)
        self._build_nodes(x, y, criterion, np.arange(x.shape[0]), self.root)

    def predict(self, x: np.ndarray) -> np.ndarray:
        return self.predict_proba(x).argmax(axis=1)

    def predict_proba(self, x: np.ndarray) -> np.ndarray:
        predictions = np.zeros((x.shape[0], self.n_classes))
        self._get_nodes_predictions(x, predictions, np.arange(x.shape[0]), self.root)
        return predictions

    def feature_importance_(self) -> np.ndarray:
        """
        Returns
        -------
        importance : cumulative improvement per feature, np.ndarray.shape = (n_features, )
        """
        importance = {}
        def traverse(node):
            if node is None or node.feature_id is None:
                return
            if self.max_depth is not None and self.max_depth <= node.depth:
                return
            if node.feature_id in importance:
                importance[node.feature_id] += node.q_value_max
            else:
                importance[node.feature_id] = node.q_value_max
            traverse(node.left_child)
            traverse(node.right_child)

        traverse(self.root)



        raise NotImplementedError("Put your code here")

class RegressionTree(DecisionTree):
    def __init__(self, criterion: str = "mse", **kwargs):
        super().__init__(**kwargs)

        if criterion not in ["mse"]:
            raise ValueError('Unsupported criterion', criterion)
        self.criterion = criterion
        self.n_classes = 0
        self.n_features = 0
        self.root = None

    def fit(self, x, y):
        self.n_classes = np.unique(y).shape[0]
        self.n_features = x.shape[1]
        criterion = None
        if self.criterion == "mse":
            criterion = MSECriterion()

        self.root = TreeNode(depth=0)
        self._build_nodes(x, y, criterion, np.arange(x.shape[0]), self.root)

    def predict(self, x: np.ndarray) -> np.ndarray:
        predictions = np.zeros(x.shape[0])
        self._get_nodes_predictions(x, predictions, np.arange(x.shape[0]), self.root)
        return predictions

